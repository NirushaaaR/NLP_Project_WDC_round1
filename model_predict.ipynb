{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import deepcut\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ยูนิคอร์นเป็นสัตว์ในตำนานซึ่งมีการอธิบายมาแต่โบราณว่าเป็นสัตว์ที่มีเขาเกลียวแหลมขนาดใหญ่ออกมาจากหน้าผาก มีการพรรณนายูนิคอร์นในตราโบราณของอารยธรรมลุ่มแม่น้ำสินธุและชาวกรีกโบราณกล่าวถึงยูนิคอร์นในบันทึกประวัติศาสตร์ธรรมชาติโดยนักเขียนหลายคน', 'เขาของสัตว์ตัวนั้นช่างสวยงาม', 'Horn แปลว่าเขา', 'Horn คือเขา', 'เขามีราคาแพง', 'เขาหาได้ยาก', 'Horny animal แปลว่าสัตว์มีเขา', 'ควายเป็นสัตว์มีเขา', 'กวางมีเขาสวยงาม', 'กวางมีเขาที่มีกิ่งสวยงาม']\n",
      "['\\ufeff1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n"
     ]
    }
   ],
   "source": [
    "# Read Input and sequence number\n",
    "read_input = [i.replace(\"\\n\", '') for i in open(\"input.txt\", encoding=\"utf8\")]\n",
    "\n",
    "input_sentence = [r.split(\"::\")[1] for r in  read_input]\n",
    "input_sentence_num = [r.split(\"::\")[0] for r in  read_input]\n",
    "\n",
    "print(input_sentence[:10])\n",
    "print(input_sentence_num[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create word vector and Sentence vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_length = 21 # only allow 21 long of input\n",
    "\n",
    "# find all available vocab\n",
    "words = [[w for w in deepcut.tokenize(s) if w != ' '] for s in input_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ต้อง', 'รีบ', 'ข้าม', 'เขา', 'ก่อน', 'มืด'], ['เขา', 'ลูก', 'นี้', 'มี', 'สัตว์', 'ร้าย', 'อาศัย', 'อยู่'], ['ตั้งเต้น', 'บน', 'เขา', 'กัน', 'เถอะ'], ['ไม่', 'มี', 'ใคร', 'รอดกลับ', 'มา', 'ถ้า', 'ขึ้น', 'เขา', 'ลูก', 'นี้', 'ไป'], ['เจ้าแน่ใจ', 'ว่า', 'จะ', 'ตาม', 'ข้า', 'ขึ้น', 'ไป', 'บน', 'เขา'], ['ฉัน', 'เห็น', 'คน', 'ขับ', 'เครื่อง', 'ร่อน', 'ลอย', 'ข้าม', 'เขา', 'ไป'], ['เครื่อง', 'บิน', 'บิน', 'ข้าม', 'เขา', 'ไป', 'อย่าง', 'ยากลำบาก'], ['เขา', 'ใกล้', 'ถล่ม', 'ลง', 'มา', 'แล้ว', 'รีบ', 'หนี', 'เร็ว'], ['จังหวัด', 'ของ', 'เขา', 'ล้อม', 'รอบ', 'ไป', 'ด้วย', 'ทะเล'], ['เขา', 'นั่น', 'คง', 'ราคา', 'ดี', 'ไม่', 'น้อย', 'เลย'], ['เขา', 'หน่ะ', 'ช่าง', 'เป็น', 'คน', 'ที่', 'ดี'], ['ฉัน', 'จะ', 'ขึ้น', 'ไป', 'บน', 'ยอด', 'เขาเอเวอร์เรส'], ['เขา', 'ชิ้น', 'นั่น', 'คง', 'แพง', 'หน้า', 'ดู'], ['เขา', 'ต้อง', 'เป็น', 'ราชา', 'โจร', 'สลัด', 'ได้', 'แน่นอน'], ['เขา', 'ของ', 'วัว', 'ตัว', 'นั้น', 'ช่าง', 'งดงาม'], ['เขา', 'วาน', 'ให้', 'หนู', 'เป็น', 'สาย', 'ลับ'], ['ภูเขา', 'ที่', 'สูง', 'ที่สุด', 'ใน', 'ประเทศญี่ปุ่น', 'ชื่อ', 'ฟูจิ'], ['เขา', 'มี', 'ความ', 'ฝัน', 'ใน', 'การ', 'เป็น', 'โฮตาเงะ', 'ของ', 'หมู่', 'บ้านโคโนฮะ'], ['หนุ่ม', 'ไอเดียเจ๋ง', 'นำ', 'เขา', 'ควาย', 'เหลือใช้', 'ใน', 'ชุมชน', 'มา', 'แกะสลัก', 'เป็น', 'รูป', 'สัตว์', 'ขาย', 'ราย', 'ได้', 'งาม'], ['เส้นทาง', 'เดิน', 'ป่า', 'หน้า', 'หนาว', 'แบก', 'เป้', 'ขึ้น', 'เขา', 'ลุย', 'พงไพร', 'เสพ', 'ธรรมชาติ', 'ให้', 'ฉ่ำ', 'ปอด'], ['เขา', 'ดี', 'ทุก', 'อย่าง', 'เรา', 'ก็', 'ชอบ', 'นะ', 'ไม่', 'เที่ยว', 'ไม่', 'สูบ', 'บุหรี่', 'ไม่', 'กิน', 'เหล้า', 'คน', 'ดี้', 'คน', 'ดี'], ['คน', 'อื่น', 'ล้วน', 'บอก', 'ว่า', 'เขา', 'เป็น', 'คน', 'ดี', 'นะ', 'ทั้ง', 'เพื่อน', 'ทั้ง', 'ผู้', 'ใหญ่', 'ต่าง', 'ก็', 'บอก', 'ถ้า', 'แก', 'จะ'], ['เขา', 'เป็น', 'ทุก', 'อย่าง', 'ให้', 'เธอ', 'แล้ว', 'ทำไม', 'เธอ', 'ยัง', 'ไม่', 'พอใจ', 'อีก'], ['คน', 'รัก', 'เขา', 'วัว', 'ควาย', 'ซื้อขาย', 'แลกเปลี่ยน', 'ความ', 'รู้'], ['การ', 'เดิน', 'ป่า', 'เดิน', 'เขา', 'นั้น', 'เป็น', 'การ', 'ออก', 'กำลัง', 'กาย', 'อย่าง', 'หนึ่ง'], ['เขา', 'คือ', 'พื้น', 'ดิน', 'ที่', 'ยืด', 'ตัว', 'ขึ้น', 'มา'], ['ก็', 'อย่าง', 'ว่า', 'การ', 'หลัก', 'ลอบ', 'ขาย', 'เขา', 'มัน', 'ไม่', 'ดี', 'ถึง', 'จะ', 'มี', 'ราคา', 'ก็ตาม'], ['ความ', 'รัก', 'ทำ', 'ให้', 'เขา', 'ตา', 'บอด'], ['เขา', 'ที่', 'จะ', 'เอา', 'มา', 'สู้', 'กับ', 'เจ้า', 'นั่น', 'ได้', 'ก็', 'มา', 'หา', 'จาก', 'ควาย', 'ตัว', 'นี้', 'แหละ'], ['ชาย', 'คน', 'นั้น', 'ระเบิด', 'ภูเขา', 'เผา', 'กระท่อม', 'มา', 'นัก', 'ต่อ', 'นัก']]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Extracted only the word between \"เขา\" 5 word\n",
    "def split_from_kau(words):\n",
    "    q = []\n",
    "    flag_found_kau = False\n",
    "    after_found = 0\n",
    "    for w in words:\n",
    "        q.append(w)\n",
    "        if \"เขา\" in w:\n",
    "            flag_found_kau = True\n",
    "            after_found = len(q)\n",
    "        elif flag_found_kau:\n",
    "            if len(q) >= 21:\n",
    "                break\n",
    "        else:\n",
    "            if len(q) > 10:\n",
    "                q.pop(0)\n",
    "    return q\n",
    "# print(index_of_kau(words[0]))\n",
    "words_split = [split_from_kau(w) for w in words]\n",
    "print(words_split[-30:])\n",
    "max_sentence_length = 21 # should not be larger than 21 word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([w for s in words_split for w in s])\n",
    "pretrained_word_vec_file = open('cc.th.300.vec', 'r',encoding = 'utf-8-sig')\n",
    "count = 0\n",
    "vocab_vec = {}\n",
    "for line in pretrained_word_vec_file:\n",
    "    if count > 0:\n",
    "        line = line.split()\n",
    "        if(line[0] in vocab): \n",
    "            vocab_vec[line[0]] = line[1:]\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the initial with 0\n",
    "word_vector_length = 300\n",
    "word_vectors = np.zeros((len(words_split),max_sentence_length,word_vector_length))\n",
    "sample_count = 0\n",
    "for s in words_split:\n",
    "    word_count = 0\n",
    "    for w in s:\n",
    "        try:\n",
    "            word_vectors[sample_count,max_sentence_length-word_count-1,:] = vocab_vec[w]\n",
    "            word_count = word_count+1\n",
    "        except:\n",
    "            pass\n",
    "    sample_count = sample_count+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dictlabel prepare to convert it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 0, 'P': 1, 'M': 2}\n",
      "{0: 'H', 1: 'P', 2: 'M'}\n"
     ]
    }
   ],
   "source": [
    "dict_label = {\"H\":0,\"P\":1,\"M\":2}\n",
    "dict_label_reverse = {v:k for k,v in dict_label.items()}\n",
    "print(dict_label)\n",
    "print(dict_label_reverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 21, 300)]         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 44)                56848     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 135       \n",
      "=================================================================\n",
      "Total params: 56,983\n",
      "Trainable params: 56,983\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Load model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 0.0000000e+00 1.5290514e-24]\n",
      " [9.9999964e-01 0.0000000e+00 3.0625014e-07]\n",
      " [1.0000000e+00 0.0000000e+00 8.5507566e-21]\n",
      " [1.0000000e+00 0.0000000e+00 1.0160175e-18]\n",
      " [9.9920505e-01 5.7336895e-22 7.9497776e-04]\n",
      " [1.0000000e+00 0.0000000e+00 8.0681456e-10]\n",
      " [1.0000000e+00 0.0000000e+00 6.0957825e-17]\n",
      " [1.0000000e+00 0.0000000e+00 6.1928508e-21]\n",
      " [1.0000000e+00 0.0000000e+00 9.6235730e-26]\n",
      " [1.0000000e+00 0.0000000e+00 7.8919094e-22]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(word_vectors)\n",
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'P', 'H', 'H', 'H', 'H', 'H', 'H', 'P', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'M', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'M', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'M', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'M', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'P', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'P', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'P', 'H', 'P', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'P', 'H', 'H', 'H', 'H', 'H', 'H', 'M', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'P', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'M', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'M', 'H', 'H', 'H', 'H', 'M', 'H', 'H', 'P', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'H', 'P', 'P', 'P', 'H', 'M', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'H', 'P', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'P', 'P', 'P', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'P', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'P', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'P', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'P', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'P', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'H', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'P', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'P', 'P', 'P', 'M', 'H', 'P', 'H', 'P', 'M', 'P', 'H', 'M', 'P', 'P', 'P', 'P', 'H', 'M', 'H', 'P', 'P', 'M']\n"
     ]
    }
   ],
   "source": [
    "def find_index_of_max(l):\n",
    "    i = (0,l[0])\n",
    "    for y in enumerate(l):\n",
    "        if i[1] < y[1]:\n",
    "            i = y\n",
    "    return i[0]\n",
    "\n",
    "labels = [dict_label_reverse[find_index_of_max(pred)] for pred in y_pred]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"ans.txt\", \"w\", \"utf-8\") as writer:\n",
    "    for res in zip(input_sentence_num, labels):\n",
    "        writer.write(res[0]+\"::\"+res[1]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('NLP': conda)",
   "language": "python",
   "name": "python37664bitnlpconda01760896482d47d5b516f31bea11e24d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}